{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# AI-Assisted Data Curation Toolkit: BDC Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "This notebook demonstrates the AI-Assisted Data Curation Toolkit for use cases in NHLBI BioData Catalyst.\n",
    "\n",
    "The toolkit is capable of suggesting harmonizations from a source data model into a target data model using AI-backed approaches, while leaving the expert curator in complete control.\n",
    "\n",
    "For BDC we will demonstrate the following use cases:\n",
    "\n",
    "- Assist in mapping between the new DMC BDC-HM data model (modeled in LinkML, export in JSON) and the existing NHLBI BioData Catalyst Gen3 Data Dictionary (modeled in YAML/JSON)\n",
    "- Assist in mapping from a BioLINCC study's original variables to variables in the new DMC BDC-HM data model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Let's pull the latest generated JSON Schema of the BDC HM data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/RTIInternational/NHLBI-BDC-DMC-HM/refs/heads/main/generated/bdchm.schema.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Now setup some imports from the toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from ai_harmonization.interactive import (\n",
    "    get_interactive_table_for_suggestions,\n",
    "    get_nodes_and_properties_df,\n",
    ")\n",
    "from ai_harmonization.simple_data_model import (\n",
    "    SimpleDataModel,\n",
    "    get_data_model_as_node_prop_type_descriptions,\n",
    ")\n",
    "from ai_harmonization.harmonization_approaches.similarity_inmem import (\n",
    "    SimilaritySearchInMemoryVectorDb,\n",
    ")\n",
    "from ai_harmonization.harmonization_approaches.embeddings import BGEEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Set available GPUs (skip this step is using CPUs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"  # change as necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Use a Harmonization Approach to get Suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Input \n",
    "\n",
    "- A `source data model` you want to harmonize from\n",
    "- A `target data model` you want to harmonize to\n",
    "\n",
    "For this initial example, we will evaluate two use cases: \n",
    "\n",
    "1. BDC-HM to Gen3 Data Dictionary\n",
    "- The `source data model` will be the BDC-HM model we pulled from the public repo above. File is `bdchm.schema.json`\n",
    "- The `target data model` example is the **NHLBI BioData Catalyst Gen3 Data Dictionary v4.6.5** (latest version as of 21 AUG 2025)\n",
    "\n",
    "2. Unharmonized Study to BDC-HM\n",
    "\n",
    "- The `source data model` will be: `example_real_source_model.json`, which is a real original study before ingestion into the NHLBI BioData Catalyst ecosystem (e.g. not yet harmonized). It is based off an original BioLINCC data model\n",
    "- The `target data model` will be the BDC-HM model we pulled from the public repo above. File is `bdchm.schema.json`\n",
    "\n",
    "The toolkit is genrealized for any models, so you can experiment with altering these.\n",
    "You can change this to supply your own source or target model, so long as the format follows any of the examples, or a simplified JSON format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 1. BDC-HM to BDC Gen3 Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "The first step is to parse the source and target data models into a core data schema, AKA a simple data model, which is generalized to represent both graph-like and relational models. It's simple JSON and we have utilities for parsing it from a LinkML JSON Schema output, Gen3, and from other ARPA-H AI Curation tools (but we'll leave those out of this explanation for now, since we're dealing with existing data models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file = \"bdchm.schema.json\"\n",
    "target_file = \"./examples/example_target_model_BDC.json\"\n",
    "\n",
    "with open(source_file, \"r\") as f:\n",
    "    input_source_model = json.load(f)\n",
    "\n",
    "# Note: there is a SimpleDataModel.get_from_unknown_json_format(), but since we know the format - we can specify\n",
    "input_source_model = SimpleDataModel.from_linkml_jsonschema(\n",
    "    json.dumps(input_source_model), ignore_properties_with_endings=[\"id\"]\n",
    ")\n",
    "\n",
    "with open(target_file, \"r\") as f:\n",
    "    input_target_model = json.load(f)\n",
    "\n",
    "input_target_model = SimpleDataModel.from_gen3_model(\n",
    "    json.dumps(input_target_model), ignore_properties_with_endings=[\"id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Source Model\")\n",
    "input_source_model.get_property_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Target Model\")\n",
    "input_target_model.get_property_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Use a Specific Harmonization Approach to get Suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "This could take some time depending on what hardware you're running this one. It is embedding the entire target and source models and performing in-memory vector database searches. \n",
    "\n",
    "This is a **baseline algorithm** we are using as an initial harmonization approach to prove out the concept. We plan to use a more sophisticated approach, with trained AI models, for better results in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_fn = BGEEmbeddings(model_name=\"BAAI/bge-large-en-v1.5\")\n",
    "batch_size = 32\n",
    "\n",
    "harmonization_approach = SimilaritySearchInMemoryVectorDb(\n",
    "    # A unique name for this file and embedding algorithm within the limits of the length required by the in-memory vectostore\n",
    "    vectordb_persist_directory_name=f\"{os.path.basename(target_file)[:53]}-{embedding_fn.model.name_or_path.split(\"/\")[-1][:5]}-3\",\n",
    "    input_target_model=input_target_model,\n",
    "    embedding_function=embedding_fn,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "max_suggestions_per_property = 10\n",
    "score_threshold = 0.7\n",
    "\n",
    "suggestions = harmonization_approach.get_harmonization_suggestions(\n",
    "    input_source_model=input_source_model,\n",
    "    input_target_model=input_target_model,\n",
    "    score_threshold=score_threshold,\n",
    "    k=max_suggestions_per_property,\n",
    ")\n",
    "# you may see warnings about No relevant docs being retrieved. This is okay.\n",
    "# There may not be a great mapping from every source variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Visualize Suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_df = suggestions.to_simlified_dataframe()\n",
    "table_df.sort_values(by=\"Similarity\", ascending=False, inplace=True)\n",
    "\n",
    "# Group by 'Original Node.Property' and find the index of max similarity for each group\n",
    "idx = table_df.groupby(\"Original Node.Property\")[\"Similarity\"].idxmax()\n",
    "\n",
    "# Filter DataFrame using the indices found above\n",
    "filtered_df = table_df.loc[idx]\n",
    "filtered_df.drop(columns=[\"Original Description\", \"Target Description\"], inplace=True)\n",
    "filtered_df.sort_values(by=\"Similarity\", ascending=False, inplace=True)\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Create Interactive Table for Selecting Suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "This is where an expert will go through the suggestions from the toolkit, evaluate, and use this information to inform a final harmonization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = get_interactive_table_for_suggestions(\n",
    "    table_df,\n",
    "    column_for_filtering=1,\n",
    "    # additional config for the interactive table\n",
    "    maxBytes=\"2MB\",\n",
    "    pageLength=50,\n",
    ")\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Example ITable \n",
    "![Example ITable](./examples/example_itable.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "> **Don't see the table or see an error above?** Try restarting the kernel, then try restarting jupyter lab (if that's what you're using). The installs for AnyWidgets might not be picked up yet.\n",
    "\n",
    "> **Dark Theme?** If you're using a dark theme, you might need to switch to light for the table to display properly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "You can select interactively above, but we can also just dump the entire table to a CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_df.to_csv(\n",
    "    \"./all_suggestions_1.csv\",\n",
    "    index=False,\n",
    "    na_rep=\"N/A\",\n",
    "    sep=\"\\t\",\n",
    "    quotechar='\"',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## 2 - Original BioLINCC Study to BDC-HM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "\n",
    "- The `source data model` will be: `example_real_source_model.json`, which is a real original study before ingestion into the NHLBI BioData Catalyst ecosystem (e.g. not yet harmonized). It is based off an original BioLINCC data model\n",
    "- The `target data model` will be the BDC-HM model we pulled from the public repo above. File is `bdchm.schema.json`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file_2 = \"./examples/example_real_source_model.json\"\n",
    "target_file_2 = \"bdchm.schema.json\"\n",
    "\n",
    "with open(source_file_2, \"r\") as f:\n",
    "    input_source_model_2 = json.load(f)\n",
    "\n",
    "input_source_model_2 = SimpleDataModel.from_simple_json(\n",
    "    json.dumps(input_source_model_2), ignore_properties_with_endings=[\"id\"]\n",
    ")\n",
    "\n",
    "with open(target_file_2, \"r\") as f:\n",
    "    input_target_model_2 = json.load(f)\n",
    "\n",
    "input_target_model_2 = SimpleDataModel.from_linkml_jsonschema(\n",
    "    json.dumps(input_target_model_2), ignore_properties_with_endings=[\"id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Source Model\")\n",
    "input_source_model_2.get_property_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Target Model\")\n",
    "input_target_model_2.get_property_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### Use a Specific Harmonization Approach to get Suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "This could take some time depending on what hardware you're running this one. It is embedding the entire target and source models and performing in-memory vector database searches. \n",
    "\n",
    "This is a **baseline algorithm** we are using as an initial harmonization approach to prove out the concept. We plan to use a more sophisticated approach, with trained AI models, for better results in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonization_approach_2 = SimilaritySearchInMemoryVectorDb(\n",
    "    # A unique name for this file and embedding algorithm within the limits of the length required by the in-memory vectostore\n",
    "    vectordb_persist_directory_name=f\"{os.path.basename(target_file)[:53]}-{embedding_fn.model.name_or_path.split(\"/\")[-1][:5]}-3\",\n",
    "    input_target_model=input_target_model_2,\n",
    "    embedding_function=embedding_fn,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "suggestions_2 = harmonization_approach_2.get_harmonization_suggestions(\n",
    "    input_source_model=input_source_model_2,\n",
    "    input_target_model=input_target_model_2,\n",
    "    score_threshold=score_threshold,\n",
    "    k=max_suggestions_per_property,\n",
    ")\n",
    "# you may see warnings about No relevant docs being retrieved. This is okay.\n",
    "# There may not be a great mapping from every source variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "### Visualize Suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_df_2 = suggestions_2.to_simlified_dataframe()\n",
    "table_df_2.sort_values(by=\"Similarity\", ascending=False, inplace=True)\n",
    "table_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Original Node.Property' and find the index of max similarity for each group\n",
    "idx_2 = table_df_2.groupby(\"Original Node.Property\")[\"Similarity\"].idxmax()\n",
    "\n",
    "# Filter DataFrame using the indices found above\n",
    "filtered_df_2 = table_df_2.loc[idx_2]\n",
    "filtered_df_2.drop(columns=[\"Original Description\", \"Target Description\"], inplace=True)\n",
    "filtered_df_2.sort_values(by=\"Similarity\", ascending=False, inplace=True)\n",
    "filtered_df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### Create Interactive Table for Selecting Suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_2 = get_interactive_table_for_suggestions(\n",
    "    table_df_2,\n",
    "    column_for_filtering=1,\n",
    "    # additional config for the interactive table\n",
    "    maxBytes=\"2MB\",\n",
    "    pageLength=50,\n",
    ")\n",
    "table_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "### Example ITable \n",
    "![Example ITable](./examples/example_itable_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "> **Don't see the table or see an error above?** Try restarting the kernel, then try restarting jupyter lab (if that's what you're using). The installs for AnyWidgets might not be picked up yet.\n",
    "\n",
    "> **Dark Theme?** If you're using a dark theme, you might need to switch to light for the table to display properly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "You can select interactively above, but we can also just dump the entire table to a CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_df_2.to_csv(\n",
    "    \"./all_suggestions_2.csv\",\n",
    "    index=False,\n",
    "    na_rep=\"N/A\",\n",
    "    sep=\"\\t\",\n",
    "    quotechar='\"',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "harmonization (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
