{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Training Data for Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "We'll be using a multiple negative loss function, so we need to adapt our training data to that format (anchor, positive, negative) pairs.\n",
    "\n",
    "This notebook contains the logic to generate the training data.\n",
    "\n",
    "**If you already have the training data in the right format, skip ahead to the \"Training\" notebook.**\n",
    "\n",
    "### Existing Training Data File Format\n",
    "\n",
    "Each row in the existing JSONL training file includes a source model, with desire to harmonize to a target. We then have ground truth harmonization in `expected_mappings.tsv`.\n",
    "\n",
    "The JSONL file has 3 columns: `input_source_model`, `input_target_model`, `harmonized_mapping`\n",
    "\n",
    "Those 3 columns are effectively populated by content of files:\n",
    "\n",
    "- `source_model.json` == `input_source_model`\n",
    "- `expected_mappings.tsv` == `harmonized_mapping`\n",
    "- `target_model.json` == `input_target_model`\n",
    "\n",
    "### How to convert existing training JSONL file to the format expected for embedding model training\n",
    "\n",
    "For each ground truth mapping in `harmonized_mapping`:\n",
    "\n",
    "- Extrapolate the \"negatives\" (wrong choices) by providing the same source variable but with every target variable _except_ the correct, \"positive\" one, in the harmonized mapping\n",
    "- Output a new CSV file with 3 columns: `anchor`, `positive`, `negative`\n",
    "\n",
    "Where:\n",
    "\n",
    "- `anchor` == the source variable from the harmonized mapping\n",
    "- `positive` == the target variable from the harmonized mapping\n",
    "- `negative` == every other target variable except the right one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "> **WARNING**: The below cell will take a long time on the full dataset and the resulting file is large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from ai_harmonization.simple_data_model import (\n",
    "    SimpleDataModel,\n",
    "    get_data_model_as_node_prop_type_descriptions,\n",
    ")\n",
    "\n",
    "\n",
    "def load_model(json_obj) -> SimpleDataModel | None:\n",
    "    \"\"\"\n",
    "    Attempt to parse a JSON model into a SimpleDataModel instance.\n",
    "    Returns None if parsing fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Some libraries may accept dict directly; otherwise, use json.dumps\n",
    "        return SimpleDataModel.get_from_unknown_json_format(json.dumps(json_obj))\n",
    "    except Exception as exc:\n",
    "        print(f\"Could not parse model: {exc}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_jsonl(\n",
    "    input_jsonl_path: Path,\n",
    "    output_csv_path: Path,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reads an input JSONL where each line contains:\n",
    "        - input_source_model (dict)\n",
    "        - input_target_model (dict)\n",
    "        - harmonized_mapping (Path to a TSV file with 2 columns)\n",
    "    For each source/target property pair in the TSV, writes rows of the form:\n",
    "        anchor (source description), positive (target description), negatives (any other target prop)\n",
    "    The output is a CSV file with headers: anchor,positive,negatives.\n",
    "    \"\"\"\n",
    "    # Count total lines once for a static progress bar\n",
    "    total_lines = sum(1 for _ in input_jsonl_path.open(\"r\", encoding=\"utf-8\"))\n",
    "\n",
    "    with (\n",
    "        input_jsonl_path.open(\"r\", encoding=\"utf-8\") as infile,\n",
    "        output_csv_path.open(\"w\", newline=\"\", encoding=\"utf-8\") as outfile,\n",
    "    ):\n",
    "        writer = csv.writer(outfile)\n",
    "        # header\n",
    "        writer.writerow([\"anchor\", \"positive\", \"negatives\"])\n",
    "\n",
    "        for line_no, line in tqdm(\n",
    "            enumerate(infile, start=1), total=total_lines, desc=\"Processing lines\"\n",
    "        ):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                entry = json.loads(line)\n",
    "            except json.JSONDecodeError as exc:\n",
    "                print(f\"Skipping malformed JSON at line {line_no}: {exc}\")\n",
    "                continue\n",
    "\n",
    "            # Load source & target models\n",
    "            source_model = load_model(entry.get(\"input_source_model\"))\n",
    "            target_model = load_model(entry.get(\"input_target_model\"))\n",
    "            if source_model is None or target_model is None:\n",
    "                print(f\"Skipping line {line_no} due to model parse failure.\")\n",
    "                continue\n",
    "\n",
    "            # Get all target property descriptions\n",
    "            target_props = get_data_model_as_node_prop_type_descriptions(target_model)\n",
    "\n",
    "            # Load harmonization TSV\n",
    "            for row_number, tsv_line in enumerate(\n",
    "                entry.get(\"harmonized_mapping\").split(\"\\n\"), start=1\n",
    "            ):\n",
    "                parts = tsv_line.rstrip(\"\\n\").split(\"\\t\")\n",
    "                if len(parts) != 2:\n",
    "                    print(f\"Skipping malformed TSV row {tsv_line}\")\n",
    "                    continue\n",
    "\n",
    "                source_desc, target_desc = parts\n",
    "\n",
    "                # just in case descriptions have commas, lets get rid of them so the final CSV is\n",
    "                # not malformed\n",
    "                source_desc = source_desc.replace(\",\", \";\")\n",
    "                target_desc = target_desc.replace(\",\", \";\")\n",
    "\n",
    "                # handle newlines at the beginning of file\n",
    "                if source_desc == \"ai_model_node_prop_desc\" or not source_desc:\n",
    "                    continue\n",
    "\n",
    "                # Build the list of negatives (exclude the positive itself)\n",
    "                negatives_list = [\n",
    "                    neg.replace(\",\", \";\") for neg in target_props if neg != target_desc\n",
    "                ]\n",
    "\n",
    "                # Convert the list to a JSON string\n",
    "                negatives_json = json.dumps(negatives_list)\n",
    "\n",
    "                # Write the single row\n",
    "                writer.writerow([source_desc, target_desc, negatives_json])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Change the paths below to wherever you have the existing training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = Path(\n",
    "    \"../datasets/harmonization_training_Mutated_SDCs_v3_20250423_v0.0.2/_training_data/final_training_data.jsonl\"\n",
    ")\n",
    "output_path = Path(\n",
    "    \"../datasets/embedding_training_data_v0.0.1/embedding_training_with_negatives.csv\"\n",
    ")\n",
    "process_jsonl(input_path, output_path)\n",
    "print(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-harmonization (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
